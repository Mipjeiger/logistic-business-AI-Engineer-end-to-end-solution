{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2ebb08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database path: /Users/miftahhadiyannoor/Documents/logistics-rag/railway_deployment/data/vectordb\n",
      "Path exists: True\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_community.llms import Ollama\n",
    "\n",
    "# Path to your vector database\n",
    "# Use absolute path by going up to parent directories\n",
    "current_dir = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "project_root = os.path.dirname(os.path.dirname(current_dir))\n",
    "db_path = os.path.join(project_root, \"railway_deployment\", \"data\", \"vectordb\")\n",
    "\n",
    "# Alternative: Use relative path from current file location\n",
    "# db_path = os.path.join(os.path.dirname(__file__), \"..\", \"data\", \"vectordb\")\n",
    "\n",
    "print(f\"Database path: {db_path}\")\n",
    "print(f\"Path exists: {os.path.exists(db_path)}\")\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "febacd07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Checking Vector Database Files ===\n",
      "PKL file path: /Users/miftahhadiyannoor/Documents/logistics-rag/railway_deployment/data/vectordb/index.pkl\n",
      "PKL exists: True\n",
      "FAISS file path: /Users/miftahhadiyannoor/Documents/logistics-rag/railway_deployment/data/vectordb/index.faiss\n",
      "FAISS exists: True\n",
      "\n",
      "✓ All files found! Proceeding with loading...\n",
      "\n",
      "==================================================\n",
      "=== PKL File Contents ===\n",
      "Type: <class 'tuple'>\n",
      "Keys: Not a dict\n"
     ]
    }
   ],
   "source": [
    "# === Verify files exist ===\n",
    "print(\"=== Checking Vector Database Files ===\")\n",
    "pkl_file = os.path.join(db_path, \"index.pkl\")\n",
    "faiss_file = os.path.join(db_path, \"index.faiss\")\n",
    "\n",
    "print(f\"PKL file path: {pkl_file}\")\n",
    "print(f\"PKL exists: {os.path.exists(pkl_file)}\")\n",
    "print(f\"FAISS file path: {faiss_file}\")\n",
    "print(f\"FAISS exists: {os.path.exists(faiss_file)}\")\n",
    "\n",
    "if not os.path.exists(pkl_file):\n",
    "    print(f\"\\n⚠️  PKL file not found! Available files in {db_path}:\")\n",
    "    if os.path.exists(db_path):\n",
    "        print(os.listdir(db_path))\n",
    "    else:\n",
    "        print(f\"Directory doesn't exist: {db_path}\")\n",
    "else:\n",
    "    print(\"\\n✓ All files found! Proceeding with loading...\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "pkl_file = os.path.join(db_path, \"index.pkl\")\n",
    "if os.path.exists(pkl_file):\n",
    "    with open(pkl_file, 'rb') as f:\n",
    "        pkl_data = pickle.load(f)\n",
    "    \n",
    "    print(\"=== PKL File Contents ===\")\n",
    "    print(f\"Type: {type(pkl_data)}\")\n",
    "    print(f\"Keys: {pkl_data.keys() if isinstance(pkl_data, dict) else 'Not a dict'}\")\n",
    "    \n",
    "    # If it's a docstore\n",
    "    if hasattr(pkl_data, '__dict__'):\n",
    "        print(f\"Attributes: {pkl_data.__dict__.keys()}\")\n",
    "    \n",
    "    # Try to see documents if it's a docstore\n",
    "    if isinstance(pkl_data, dict) and 'docstore' in pkl_data:\n",
    "        docstore = pkl_data['docstore']\n",
    "        print(f\"\\nDocstore type: {type(docstore)}\")\n",
    "        if hasattr(docstore, '_dict'):\n",
    "            print(f\"Number of documents: {len(docstore._dict)}\")\n",
    "            # Print first few documents\n",
    "            for i, (key, doc) in enumerate(list(docstore._dict.items())[:3]):\n",
    "                print(f\"\\nDocument {i+1}:\")\n",
    "                print(f\"  Key: {key}\")\n",
    "                print(f\"  Content preview: {doc.page_content[:200]}...\")\n",
    "else:\n",
    "    print(f\"❌ PKL file not found at {pkl_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9db8f875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS file not found at railway_deployment/data/vectordb/index.faiss\n"
     ]
    }
   ],
   "source": [
    "# === 2. Inspect .faiss file (index info) ===\n",
    "faiss_file = os.path.join(db_path, \"index.faiss\")\n",
    "if os.path.exists(faiss_file):\n",
    "    print(\"\\n=== FAISS File Info ===\")\n",
    "    print(f\"File size: {os.path.getsize(faiss_file)} bytes\")\n",
    "    \n",
    "    # You need to load it with embeddings to see more details\n",
    "    try:\n",
    "        import faiss\n",
    "        index = faiss.read_index(faiss_file)\n",
    "        print(f\"Index type: {type(index)}\")\n",
    "        print(f\"Number of vectors: {index.ntotal}\")\n",
    "        print(f\"Vector dimension: {index.d}\")\n",
    "        print(f\"Is trained: {index.is_trained}\")\n",
    "    except ImportError:\n",
    "        print(\"Install faiss-cpu to read index details: pip install faiss-cpu\")\n",
    "else:\n",
    "    print(f\"FAISS file not found at {faiss_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4493f457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Loading FAISS Database ===\n",
      "Error loading database: Error in faiss::FileIOReader::FileIOReader(const char *) at /Users/runner/work/faiss-wheels/faiss-wheels/third-party/faiss/faiss/impl/io.cpp:70: Error: 'f' failed: could not open railway_deployment/data/vectordb/index.faiss for reading: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "# === 3. Load complete FAISS database with LangChain ===\n",
    "print(\"\\n=== Loading FAISS Database ===\")\n",
    "embeddings = OllamaEmbeddings(model=\"llama3\")\n",
    "\n",
    "try:\n",
    "    db = FAISS.load_local(db_path, embeddings, allow_dangerous_deserialization=True)\n",
    "    \n",
    "    print(f\"Database loaded successfully\")\n",
    "    print(f\"Number of documents in index: {db.index.ntotal}\")\n",
    "    \n",
    "    # Get the docstore\n",
    "    if hasattr(db, 'docstore'):\n",
    "        docstore = db.docstore\n",
    "        if hasattr(docstore, '_dict'):\n",
    "            docs = list(docstore._dict.values())\n",
    "            print(f\"Total documents in docstore: {len(docs)}\")\n",
    "            \n",
    "            # Show sample documents\n",
    "            print(\"\\n=== Sample Documents ===\")\n",
    "            for i, doc in enumerate(docs[:3]):\n",
    "                print(f\"\\nDocument {i+1}:\")\n",
    "                print(f\"  Content: {doc.page_content[:300]}...\")\n",
    "                print(f\"  Metadata: {doc.metadata}\")\n",
    "\n",
    "# Test similarity search\n",
    "    print(\"\\n=== Testing Similarity Search ===\")\n",
    "    test_query = \"test query\"\n",
    "    results = db.similarity_search(test_query, k=2)\n",
    "    print(f\"Found {len(results)} similar documents for query: '{test_query}'\")\n",
    "    for i, doc in enumerate(results):\n",
    "        print(f\"\\nResult {i+1}:\")\n",
    "        print(f\"  Content: {doc.page_content[:200]}...\")\n",
    "        print(f\"  Metadata: {doc.metadata}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error loading database: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1624184a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
