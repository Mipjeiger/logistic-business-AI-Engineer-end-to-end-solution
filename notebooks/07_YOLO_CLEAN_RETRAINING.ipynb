{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9ae9207",
   "metadata": {},
   "source": [
    "# ğŸ”„ YOLO Model Retraining - Clean Dataset\n",
    "\n",
    "## Purpose\n",
    "After removing duplicate models and clearing directories, retrain YOLO model with fresh, clean dataset.\n",
    "\n",
    "**Status**: All duplicate files removed, directories cleared âœ…\n",
    "**Goal**: Create clean trained model for production\n",
    "\n",
    "---\n",
    "\n",
    "## Pipeline\n",
    "1. Import & Setup\n",
    "2. Verify Dataset\n",
    "3. Train YOLO Model\n",
    "4. Validate Results\n",
    "5. Save & Export Model\n",
    "6. Compare with Previous Model (if backup exists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca580283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1ï¸âƒ£ IMPORT & SETUP\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# YOLO\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Utilities\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "print(\"âœ… Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9074ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2ï¸âƒ£ VERIFY DATASET\n",
    "PROJECT_ROOT = '/Users/miftahhadiyannoor/Documents/logistics-rag'\n",
    "DATASET_PATH = os.path.join(PROJECT_ROOT, 'notebooks/dataset')\n",
    "DATASET_CONFIG = os.path.join(DATASET_PATH, 'data.yaml')\n",
    "\n",
    "print(\"ğŸ“Š Dataset Verification\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Check dataset exists\n",
    "if os.path.exists(DATASET_CONFIG):\n",
    "    print(f\"âœ… Dataset config found: {DATASET_CONFIG}\")\n",
    "    \n",
    "    # Read YAML\n",
    "    import yaml\n",
    "    with open(DATASET_CONFIG, 'r') as f:\n",
    "        dataset_info = yaml.safe_load(f)\n",
    "    \n",
    "    print(f\"\\nğŸ“ Dataset structure:\")\n",
    "    for key, value in dataset_info.items():\n",
    "        if key in ['train', 'val', 'test']:\n",
    "            path = os.path.join(DATASET_PATH, value)\n",
    "            exists = os.path.exists(path)\n",
    "            status = \"âœ…\" if exists else \"âŒ\"\n",
    "            count = len(os.listdir(path)) if exists else 0\n",
    "            print(f\"  {status} {key}: {count} items\")\n",
    "    \n",
    "    print(f\"\\nğŸ“‹ Classes: {dataset_info.get('names', {})}\")\n",
    "else:\n",
    "    print(f\"âŒ Dataset config not found: {DATASET_CONFIG}\")\n",
    "    print(f\"   Please ensure data.yaml exists in {DATASET_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c154ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3ï¸âƒ£ LOAD PRETRAINED YOLO & PREPARE FOR TRAINING\n",
    "print(\"\\nğŸ¤– Loading YOLO Base Model\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Load a pretrained YOLOv8 model (small for faster training)\n",
    "model = YOLO('yolov8n.pt')\n",
    "print(f\"âœ… Base model loaded: yolov8n\")\n",
    "print(f\"   Model parameters: {sum(p.numel() for p in model.model.parameters() if p.requires_grad):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7235a053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4ï¸âƒ£ TRAIN YOLO MODEL ON CLEAN DATASET\n",
    "print(\"\\nğŸš€ Starting YOLO Training\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Training configuration\n",
    "EPOCHS = 100\n",
    "IMG_SIZE = 640\n",
    "BATCH_SIZE = 16\n",
    "PATIENCE = 20  # Early stopping\n",
    "\n",
    "print(f\"ğŸ“‹ Training Config:\")\n",
    "print(f\"   Epochs: {EPOCHS}\")\n",
    "print(f\"   Image Size: {IMG_SIZE}\")\n",
    "print(f\"   Batch Size: {BATCH_SIZE}\")\n",
    "print(f\"   Early Stopping Patience: {PATIENCE}\")\n",
    "print(f\"   Dataset: {DATASET_CONFIG}\")\n",
    "\n",
    "# Train the model\n",
    "results = model.train(\n",
    "    data=DATASET_CONFIG,\n",
    "    epochs=EPOCHS,\n",
    "    imgsz=IMG_SIZE,\n",
    "    batch=BATCH_SIZE,\n",
    "    patience=PATIENCE,\n",
    "    device=0,  # GPU device 0\n",
    "    save=True,\n",
    "    project='runs/detect',\n",
    "    name='train_clean',  # New clean training run\n",
    "    exist_ok=False,  # Don't overwrite\n",
    "    verbose=True,\n",
    "    plots=True  # Generate plots\n",
    ")\n",
    "\n",
    "print(f\"\\nâœ… Training complete!\")\n",
    "print(f\"   Results saved to: runs/detect/train_clean/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead7b2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5ï¸âƒ£ VALIDATE MODEL ON TEST SET\n",
    "print(\"\\nğŸ” Model Validation\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Load best model\n",
    "best_model = YOLO('runs/detect/train_clean/weights/best.pt')\n",
    "\n",
    "# Validate on validation set\n",
    "val_results = best_model.val()\n",
    "\n",
    "print(f\"\\nâœ… Validation Metrics:\")\n",
    "print(f\"   mAP50: {val_results.box.map50:.3f}\")\n",
    "print(f\"   mAP50-95: {val_results.box.map:.3f}\")\n",
    "print(f\"   Precision: {val_results.box.mp:.3f}\")\n",
    "print(f\"   Recall: {val_results.box.mr:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819b41b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6ï¸âƒ£ DISPLAY TRAINING RESULTS\n",
    "print(\"\\nğŸ“ˆ Training Results Visualization\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Paths to result images\n",
    "results_dir = 'runs/detect/train_clean'\n",
    "result_images = [\n",
    "    'results.png',\n",
    "    'confusion_matrix.png',\n",
    "    'confusion_matrix_normalized.png'\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, img_name in enumerate(result_images):\n",
    "    img_path = os.path.join(results_dir, img_name)\n",
    "    if os.path.exists(img_path):\n",
    "        img = cv2.imread(img_path)\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        axes[idx].imshow(img_rgb)\n",
    "        axes[idx].set_title(img_name.replace('.png', '').replace('_', ' ').title())\n",
    "        axes[idx].axis('off')\n",
    "    else:\n",
    "        axes[idx].text(0.5, 0.5, f'Not found: {img_name}', \n",
    "                      ha='center', va='center')\n",
    "        axes[idx].set_title(img_name)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ… Results displayed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60792842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7ï¸âƒ£ EXPORT TRAINED MODEL\n",
    "print(\"\\nğŸ’¾ Exporting Trained Model\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Copy best model to production location\n",
    "import shutil\n",
    "\n",
    "SOURCE_MODEL = 'runs/detect/train_clean/weights/best.pt'\n",
    "EXPORT_LOCATIONS = [\n",
    "    'production_api/model/best.pt',\n",
    "    'deployment/models/best.pt',\n",
    "    'yolov8-container-inspection/best.pt'\n",
    "]\n",
    "\n",
    "for dest in EXPORT_LOCATIONS:\n",
    "    os.makedirs(os.path.dirname(dest), exist_ok=True)\n",
    "    shutil.copy(SOURCE_MODEL, dest)\n",
    "    print(f\"  âœ… Model copied to: {dest}\")\n",
    "\n",
    "print(f\"\\nâœ… Model exported to all locations!\")\n",
    "\n",
    "# Get model size\n",
    "model_size = os.path.getsize(SOURCE_MODEL) / (1024*1024)\n",
    "print(f\"   Model size: {model_size:.2f}MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b66264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8ï¸âƒ£ TEST MODEL ON SAMPLE IMAGE\n",
    "print(\"\\nğŸ§ª Testing Model on Sample\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Load trained model\n",
    "test_model = YOLO('runs/detect/train_clean/weights/best.pt')\n",
    "\n",
    "# Find a sample image from validation set\n",
    "val_images_dir = os.path.join(DATASET_PATH, 'images/val')\n",
    "\n",
    "if os.path.exists(val_images_dir):\n",
    "    images = [f for f in os.listdir(val_images_dir) if f.endswith(('.jpg', '.png'))]\n",
    "    \n",
    "    if images:\n",
    "        # Test on first image\n",
    "        test_image_path = os.path.join(val_images_dir, images[0])\n",
    "        print(f\"   Testing on: {images[0]}\")\n",
    "        \n",
    "        # Run inference\n",
    "        results = test_model.predict(test_image_path)\n",
    "        \n",
    "        # Display results\n",
    "        result = results[0]\n",
    "        annotated_frame = result.plot()\n",
    "        \n",
    "        # Show\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        plt.imshow(cv2.cvtColor(annotated_frame, cv2.COLOR_BGR2RGB))\n",
    "        plt.title(f\"Detection Results: {len(result.boxes)} objects detected\")\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "        \n",
    "        print(f\"\\nâœ… Detections: {len(result.boxes)} objects\")\n",
    "        \n",
    "        # Show class distribution\n",
    "        if len(result.boxes) > 0:\n",
    "            print(f\"\\n   Classes detected:\")\n",
    "            for cls_id, cls_name in dataset_info['names'].items():\n",
    "                count = (result.boxes.cls == cls_id).sum().item()\n",
    "                if count > 0:\n",
    "                    print(f\"     - {cls_name}: {count}\")\n",
    "    else:\n",
    "        print(f\"âŒ No validation images found in {val_images_dir}\")\n",
    "else:\n",
    "    print(f\"âŒ Validation directory not found: {val_images_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebc10d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9ï¸âƒ£ SUMMARY & NEXT STEPS\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"âœ… YOLO RETRAINING COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nğŸ“Š Summary:\")\n",
    "print(f\"   âœ… Trained on clean dataset\")\n",
    "print(f\"   âœ… Model validated\")\n",
    "print(f\"   âœ… Model exported to production locations\")\n",
    "print(f\"   âœ… Sample inference tested\")\n",
    "\n",
    "print(f\"\\nğŸ“ Output Locations:\")\n",
    "print(f\"   Training results: runs/detect/train_clean/\")\n",
    "print(f\"   Best model: runs/detect/train_clean/weights/best.pt\")\n",
    "print(f\"   Validation plots: runs/detect/train_clean/\")\n",
    "\n",
    "print(f\"\\nğŸš€ Next Steps:\")\n",
    "print(f\"   1. Regenerate vector database (07_VECTOR_DB_REGEN.ipynb)\")\n",
    "print(f\"   2. Test production pipeline\")\n",
    "print(f\"   3. Monitor model performance in production\")\n",
    "\n",
    "print(f\"\\nâœ¨ Status: Ready for production!\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
